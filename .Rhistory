?mean
?mean
library(RANN)
setwd('/home/marc/Desktop/crime_data/')
# Read in the Crime data.
df <- read.csv("Crime_Data_from_2010_to_Present.csv")
# Get rid of huge spaces in address and cross street
df$Address <- gsub("[ \t]{1,}", ' ', as.character(df$Address))
df$Cross.Street <- gsub("[ \t]{1,}", ' ', as.character(df$Cross.Street))
# From the inside out - get the Location column as character - strip
# the parenthesis from the GPS data - split the data on the comma -
# turn the result into a matrix with rbind
loc_temp <- do.call(
rbind, strsplit(
gsub("\\(|\\)", '', as.character(df$Location)),
',')
)
# Create Lat and Lon columns as floats instead of characters
df$Lat <- as.numeric(loc_temp[,1])
df$Lon <- as.numeric(loc_temp[,2])
rm(loc_temp)
# Drop Location column as it's data is now Lat and Lon
df$Location <- NULL
#Drop any rows that have Lat and Lon equal to 0
df <- subset(df, Lat!=0)
df <- subset(df, Lon!=0)
# really was a waste of time ----------------------------------------------
# # Add leading zeros to military time and regexing for insertion
# # of colon plus adding the ":00" for seconds
# temp <- paste(
#   trimws(
#     gsub('(?=(?:.{2})$)', ":", sprintf("%04.0f", df$Time.Occurred), perl=TRUE),
#     "r"),
#   ":00",sep='')
#
# # Concat Date,Occurred and formatted time
# temp <- paste(df$Date.Occurred, temp)
#
# # Add back into dataframe as datetime
# df$datetime <- strptime(temp, "%m/%d/%Y %H:%M:%S", tz="America/Los_Angeles")
# rm(temp)
#
# # Drop Time.Occurred and Date.Occurred as the info is in datetime
# df$Time.Occurred <- NULL
# df$Date.Occurred <- NULL
# instead doing this ------------------------------------------------------
df$Date.Occurred <- as.Date(df$Date.Occurred, format = "%m/%d/%Y")
df$Date.Reported <- as.Date(df$Date.Reported, format = "%m/%d/%Y")
# url <- 'https://aqs.epa.gov/api/api/rawData?user=mlytle4218%40gmail.com&pw=greycrane41&format=DMCSV&pc=AQI+POLLUTANTS&param=81102&bdate=20180101&edate=20190417&state=06&county=037&=Submit'
# download.file(url, 'check.csv', 'auto')
# Load in air data
df_pm10_1 <- read.csv("pm10_1.csv")
df_pm10_2 <- read.csv("pm10_2.csv")
df_pm10_3 <- read.csv("pm10_3.csv")
# combine them together
df_pm10 <- rbind(df_pm10_1,df_pm10_2,df_pm10_3)
# get rid of the old data frames
rm(df_pm10_1,df_pm10_2,df_pm10_3)
# Get rid of rows with missing important data
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Sample.Measurement))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Latitude))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Longitude))
# Create data frames for nearest neighbor search
# df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
# nn <- nn2(df_zips_coords, df_pm10_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
# df_pm10$zipcode <- df_zips$Zipcode[nn[[1]] ]
# head(df_pm10)
# unique(df_pm10$zipcode)
# nn[[1]]
head(df_pm10)
# Create data frames for nearest neighbor search
df_crime_coords <- data.frame(df_crime$Lat,df_crime$Lon)
df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
df_crime$site.num <- df_pm10$Site.Num[nn[[1]] ]
rm(df_crime_coords)
rm(df_pm10_coords)
rm(nn)
rm(list=ls())
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_coords, k=1)
library(RANN)
setwd('/home/marc/Desktop/crime_data/')
# Read in the Crime data.
df_crime <- read.csv("Crime_Data_from_2010_to_Present.csv")
# Get rid of huge spaces in address and cross street
df_crime$Address <- gsub("[ \t]{1,}", ' ', as.character(df_crime$Address))
df_crime$Cross.Street <- gsub("[ \t]{1,}", ' ', as.character(df_crime$Cross.Street))
# From the inside out - get the Location column as character - strip
# the parenthesis from the GPS data - split the data on the comma -
# turn the result into a matrix with rbind
loc_temp <- do.call(
rbind, strsplit(
gsub("\\(|\\)", '', as.character(df_crime$Location)),
',')
)
# Create Lat and Lon columns as floats instead of characters
df_crime$Lat <- as.numeric(loc_temp[,1])
df_crime$Lon <- as.numeric(loc_temp[,2])
rm(loc_temp)
# Drop Location column as it's data is now Lat and Lon
df_crime$Location <- NULL
#Drop any rows that have Lat and Lon equal to 0
df_crime <- subset(df_crime, Lat!=0)
df_crime <- subset(df_crime, Lon!=0)
# really was a waste of time ----------------------------------------------
# # Add leading zeros to military time and regexing for insertion
# # of colon plus adding the ":00" for seconds
# temp <- paste(
#   trimws(
#     gsub('(?=(?:.{2})$)', ":", sprintf("%04.0f", df$Time.Occurred), perl=TRUE),
#     "r"),
#   ":00",sep='')
#
# # Concat Date,Occurred and formatted time
# temp <- paste(df$Date.Occurred, temp)
#
# # Add back into dataframe as datetime
# df$datetime <- strptime(temp, "%m/%d/%Y %H:%M:%S", tz="America/Los_Angeles")
# rm(temp)
#
# # Drop Time.Occurred and Date.Occurred as the info is in datetime
# df$Time.Occurred <- NULL
# df$Date.Occurred <- NULL
# instead doing this ------------------------------------------------------
df_crime$Date.Occurred <- as.Date(df_crime$Date.Occurred, format = "%m/%d/%Y")
df_crime$Date.Reported <- as.Date(df_crime$Date.Reported, format = "%m/%d/%Y")
# url <- 'https://aqs.epa.gov/api/api/rawData?user=mlytle4218%40gmail.com&pw=greycrane41&format=DMCSV&pc=AQI+POLLUTANTS&param=81102&bdate=20180101&edate=20190417&state=06&county=037&=Submit'
# download.file(url, 'check.csv', 'auto')
# Load in air data
df_pm10_1 <- read.csv("pm10_1.csv")
df_pm10_2 <- read.csv("pm10_2.csv")
df_pm10_3 <- read.csv("pm10_3.csv")
# combine them together
df_pm10 <- rbind(df_pm10_1,df_pm10_2,df_pm10_3)
# get rid of the old data frames
rm(df_pm10_1,df_pm10_2,df_pm10_3)
# Get rid of rows with missing important data
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Sample.Measurement))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Latitude))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Longitude))
# Create data frames for nearest neighbor search
# df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
# nn <- nn2(df_zips_coords, df_pm10_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
# df_pm10$zipcode <- df_zips$Zipcode[nn[[1]] ]
# head(df_pm10)
# unique(df_pm10$zipcode)
# nn[[1]]
# # Read in zip code info
# df_zips <- read.csv("free-zipcode-database-Primary.csv")
#
# # Limit to only in CA
# df_zips <- subset(df_zips, State=='CA')
# Create data frames for nearest neighbor search
df_crime_coords <- data.frame(df_crime$Lat,df_crime$Lon)
df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
df_crime$site.num <- df_pm10$Site.Num[nn[[1]] ]
rm(df_crime_coords)
rm(df_pm10_coords)
rm(nn)
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
df_crime$site.num <- df_pm10$Site.Num[nn[[1]] ]
rm(df_crime_coords)
rm(df_pm10_coords)
rm(nn)
# Create data frames for nearest neighbor search
df_crime_coords <- data.frame(df_crime$Lat,df_crime$Lon)
df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
df_crime$site.num <- df_pm10$Site.Num[nn[[1]] ]
rm(df_crime_coords)
rm(df_pm10_coords)
rm(nn)
head(df_crime)
table(df_crime)
str(df_crime)
unique(df_crime$site.num)
unique(df_crime$Lat)
unique(df_pm10$Latitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# Create data frames for nearest neighbor search
df_crime_coords <- data.frame(df_crime$Lat,df_crime$Lon)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
head(nn)
head(nn[[0]])
head(nn[[1]])
head(nn[1)
head(nn[1])
unique(nn[1])
unique(df_crime$Lat)
unique(nn)
unique(nn[[1]])
unique(df_pm10$Site.Num[nn[[1]] ])
nn2 <- nn2(df_crime_coords, df_pm10_coords, k=1)
unique(nn2[[1]])
rm(nn2)
rm(df_pm10_coords)
rm(nn)
rm(df_crime_coords)
unique(df_crime$site.num)
min(df_crime$Lat)
min(df_crime$Lon)
max(df_crime$Lat)
max(df_crime$Lon)
min(df_pm10$Latitude, df_pm10$Longitude)
min(df_pm10$Latitude)
df_pm10$Latitude <- as.numeric(df_pm10$Latitude)
df_pm10$Longitude <- as.numeric(df_pm10$Longitude)
df_pm10_coords <- data.frame(df_pm10$Latitude,df_pm10$Longitude)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
# Create data frames for nearest neighbor search
df_crime_coords <- data.frame(df_crime$Lat,df_crime$Lon)
# run nearest neighbor search
# was counter intuitive to me - first the data you are trying
# match to and then the data you are trying to match with then
# the number of matches you want
nn <- nn2(df_pm10_coords, df_crime_coords, k=1)
# the result as the index to the get the zip codes and then pass
# them into the crime dataframe
df_crime$site.num <- df_pm10$Site.Num[nn[[1]] ]
unique(df_crime$site.num)
min(df_pm10$Latitude, df_pm10$Longitude)
min(df_pm10$Longitude)
min(df_pm10$Latitude)
#Drop any rows that have Lat and Lon equal to 0
df_pm10 <- subset(df_pm10, Latitude!=0)
df_pm10 <- subset(df_pm10, Longitude!=0)
min(df_pm10$Latitude)
#Drop any rows that have Lat and Lon equal to 0
df_pm10 <- subset(df_pm10, Latitude!=1)
df_pm10 <- subset(df_pm10, Longitude!=1)
min(df_pm10$Latitude)
df_pm10 <- subset(df_pm10, Latitude!=2)
df_pm10 <- subset(df_pm10, Longitude!=2)
min(df_pm10$Latitude)
df_pm10_1 <- read.csv("pm10_1.csv")
df_pm10_2 <- read.csv("pm10_2.csv")
df_pm10_3 <- read.csv("pm10_3.csv")
# combine them together
df_pm10 <- rbind(df_pm10_1,df_pm10_2,df_pm10_3)
# get rid of the old data frames
rm(df_pm10_1,df_pm10_2,df_pm10_3)
# Get rid of rows with missing important data
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Sample.Measurement))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Latitude))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Longitude))
rm(df_crime_coords)
rm(df_pm10_coords)
rm(nn)
library(rworldmap)
install.packages("rworldmap")
library(rworldmap)
newmap <- getMap(resolution = 'low')
min(df_pm10$Latitude)
df_pm10$Latitude <- as.numeric(df_pm10$Latitude)
df_pm10$Longitude <- as.numeric(df_pm10$Longitude)
min(df_pm10$Latitude)
miax(df_pm10$Latitude)
max(df_pm10$Latitude)
unique(df_pm10$Latitude)
unique(df_pm10$Longitude)
head(df_pm10)
df_pm10_1 <- read.csv("pm10_1.csv")
df_pm10_2 <- read.csv("pm10_2.csv")
df_pm10_3 <- read.csv("pm10_3.csv")
# combine them together
df_pm10 <- rbind(df_pm10_1,df_pm10_2,df_pm10_3)
# get rid of the old data frames
rm(df_pm10_1,df_pm10_2,df_pm10_3)
# Get rid of rows with missing important data
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Sample.Measurement))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Latitude))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Longitude))
head(df_pm10)
df_pm10$Latitude <- as.numeric(df_pm10$Latitude)
head(df_pm10)
df_pm10_1 <- read.csv("pm10_1.csv")
df_pm10_2 <- read.csv("pm10_2.csv")
df_pm10_3 <- read.csv("pm10_3.csv")
# combine them together
df_pm10 <- rbind(df_pm10_1,df_pm10_2,df_pm10_3)
# get rid of the old data frames
rm(df_pm10_1,df_pm10_2,df_pm10_3)
# Get rid of rows with missing important data
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Sample.Measurement))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Latitude))
df_pm10 <- subset(df_pm10, !is.na(df_pm10$Longitude))
head(df_pm10)
str(df_pm10)
df_pm10$Lat <- as.numeric( levels( df_pm10$Latitude  ) )[df_pm10$Latitude]
str(df_pm10)
head(df_pm10)
unique(df_pm10$Lat)
df_pm10$Latitude <- as.numeric( levels( df_pm10$Latitude  ) )[df_pm10$Latitude]
df_pm10$Lat <- NULL
head(df_pm10)
min(df_pm10$Latitude)
max(df_pm10$Latitude)
?round
floor(min(df_pm10$Latitude))
ceiling(min(df_pm10$Latitude))
ceiling(max(df_pm10$Latitude))
plot( newmap, xlim = c(floor(min(df_pm10$Longitude)), ceiling(max(df_pm10$Longitude))), ylim= c(floor(min(df_pm10$Latitude)), ceiling(max(df_pm10$Latitude))), asp = 1)
points(df_pm10$Latitude, df_pm10$Longitude, col='red', cex = 0.6)
points(df_pm10$Latitude, df_pm10$Longitude, col="red", cex = .6)
points(df_pm10$Longitude, df_pm10$Latitude, col="red", cex = .6)
points(df_crime$Lon, df_crime$Lat, col = "blue", cex =.6)
# loading the required packages
library(ggplot2)
library(ggmap)
install.packages("ggmap")
# getting the map
mapgilbert <- get_map(location = c(lon = mean(df_pm10$Longitude), lat = mean(df_pm10$Latitude)), zoom = 4, maptype = "satellite", scale = 2)
# getting the map
mapgilbert <- get_map(location = c(lon = mean(df_pm10$Longitude), lat = mean(df_pm10$Latitude)), zoom = 4, maptype = "satellite", scale = 2)
# plotting the map with some points on it
ggmap(mapgilbert) + geom_point(data = df_pm10, aes(x = lon, y = lat, fill = "red", alpha = 0.8), size = 5, shape = 21) + guides(fill=FALSE, alpha=FALSE, size=FALSE)
